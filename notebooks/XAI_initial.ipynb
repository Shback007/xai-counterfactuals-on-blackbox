{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cae4a3-f4e0-43f8-a333-b17085778231",
   "metadata": {},
   "source": [
    "# An Introduction to XAI for Opaque models and the research objectives\n",
    "\n",
    "#### Objective:\n",
    "Develop methods for interpreting black‐box models (like deep neural networks) by comparing techniques such as LIME, SHAP, Anchors, and saliency maps. We will evaluate these methods on different datasets and model architectures, propose a benchmark for explanation quality (e.g., fidelity), and discuss trade‐offs (fidelity vs. interpretability).\n",
    "#### Environment & Dataset Setup:\n",
    "How to install the necessary Python packages and load two example datasets: a tabular dataset (Breast Cancer from scikit‐learn) and an image dataset (MNIST).\n",
    "#### Model Building:\n",
    "Constructing a feedforward neural network for the tabular dataset and a CNN for MNIST.\n",
    "#### Explainability Techniques:\n",
    "- Using LIME and SHAP on the tabular model.\n",
    "- Explaining a CNN via saliency maps on MNIST.\n",
    "- Running a simple Anchors explanation (using the Alibi library).\n",
    "- Implementing a hybrid approach by combining LIME and SHAP explanations.\n",
    "#### Benchmarking & Evaluation:\n",
    "A simplified fidelity metric (how much the prediction drops when top features are perturbed) and evaluation over multiple instances.\n",
    "#### Visualization & Comparative Analysis:\n",
    "Visualizing explanations and summarizing quantitative results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f74f4-4868-42c6-827e-dd6091c4dc0d",
   "metadata": {},
   "source": [
    "## Environmental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873d2558-2085-4de6-a7be-5e10bb97b8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Import XAI libraries\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import shap\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c108b-329c-4e7e-8405-3ff50f948104",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a6c6b-f3ca-43be-936a-13727ecb23a8",
   "metadata": {},
   "source": [
    "> ### Image Data Example (MNIST Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9be8474-7dae-4632-8970-0c6cd01547e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset shape: (60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train_img, y_train_img), (X_test_img, y_test_img) = mnist.load_data()\n",
    "\n",
    "# Normalize images and add channel dimension\n",
    "X_train_img = X_train_img.astype('float32') / 255.0\n",
    "X_test_img = X_test_img.astype('float32') / 255.0\n",
    "\n",
    "X_train_img = np.expand_dims(X_train_img, -1)\n",
    "X_test_img = np.expand_dims(X_test_img, -1)\n",
    "\n",
    "# One-hot encode labels for classification\n",
    "y_train_img_cat = to_categorical(y_train_img, 10)\n",
    "y_test_img_cat = to_categorical(y_test_img, 10)\n",
    "\n",
    "print(\"MNIST dataset shape:\", X_train_img.shape, X_test_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05badd1-fb35-4d1b-90ba-027223bee55e",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e83943-ddb6-49b1-a9ed-cf70f8b3e06d",
   "metadata": {},
   "source": [
    "> ### Image Model: CNN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3fa344-11e9-4467-a0c2-58403826d22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Source Codes\\AIML\\final_year_paper\\myenv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.8447 - loss: 0.5319 - val_accuracy: 0.9815 - val_loss: 0.0655\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - accuracy: 0.9825 - loss: 0.0600 - val_accuracy: 0.9857 - val_loss: 0.0488\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9861 - loss: 0.0464 - val_accuracy: 0.9852 - val_loss: 0.0478\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9901 - loss: 0.0305 - val_accuracy: 0.9900 - val_loss: 0.0370\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9924 - loss: 0.0236 - val_accuracy: 0.9910 - val_loss: 0.0336\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0422\n",
      "MNIST model accuracy: 0.989300012588501\n"
     ]
    }
   ],
   "source": [
    "# Build a simple CNN for MNIST\n",
    "def build_mnist_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=X_train_img.shape[1:]))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "mnist_model = build_mnist_model()\n",
    "history = mnist_model.fit(X_train_img, y_train_img_cat, epochs=5, batch_size=128, validation_split=0.1, verbose=1)\n",
    "test_loss, test_acc = mnist_model.evaluate(X_test_img, y_test_img_cat)\n",
    "print(\"MNIST model accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e39485-d13f-4b3d-816f-4ca94540526b",
   "metadata": {},
   "source": [
    "## Explainability AI Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a346a2c-402b-481c-989b-ca44346dec41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9cdf84-5352-4113-bb48-0b75fea52657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bbe043-89f5-46ea-afe2-7ba63b83de98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc65c338-76e3-4d03-975c-705759824ce0",
   "metadata": {},
   "source": [
    "## Saliency Maps for the CNN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf11695-2e8a-4c7a-9534-60718db3aced",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Select a sample image from the test set\u001b[39;00m\n\u001b[32m     19\u001b[39m sample_index = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m sample_image = \u001b[43mx_test_img\u001b[49m[sample_index]\n\u001b[32m     21\u001b[39m predicted_class = np.argmax(model_cnn.predict(sample_image.reshape(\u001b[32m1\u001b[39m, \u001b[32m28\u001b[39m, \u001b[32m28\u001b[39m, \u001b[32m1\u001b[39m)))\n\u001b[32m     22\u001b[39m saliency_map = compute_saliency(model_cnn, sample_image, predicted_class)\n",
      "\u001b[31mNameError\u001b[39m: name 'x_test_img' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def compute_saliency(model, image, target_class):\n",
    "    \"\"\"\n",
    "    Compute a saliency map for a given input image and target class.\n",
    "    \"\"\"\n",
    "    image_tensor = tf.convert_to_tensor(image.reshape(1, 28, 28, 1))\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image_tensor)\n",
    "        predictions = model(image_tensor)\n",
    "        loss = predictions[:, target_class]\n",
    "    # Compute gradients of the target class score with respect to the input image\n",
    "    grads = tape.gradient(loss, image_tensor)\n",
    "    # Process gradients: take maximum across color channels and absolute values\n",
    "    saliency = tf.reduce_max(tf.abs(grads), axis=-1).numpy().squeeze()\n",
    "    return saliency\n",
    "\n",
    "# Select a sample image from the test set\n",
    "sample_index = 0\n",
    "sample_image = x_test_img[sample_index]\n",
    "predicted_class = np.argmax(model_cnn.predict(sample_image.reshape(1, 28, 28, 1)))\n",
    "saliency_map = compute_saliency(model_cnn, sample_image, predicted_class)\n",
    "\n",
    "# Visualize the original image and its saliency map\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original MNIST Image\")\n",
    "plt.imshow(sample_image.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Saliency Map\")\n",
    "plt.imshow(saliency_map, cmap='jet')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284dffa1-86a9-4b4d-90d4-37ae9f053d9d",
   "metadata": {},
   "source": [
    "## Hybrid Approach: Combining LIME and SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "720c7708-76ea-43d1-9738-71991aa146e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_lime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get LIME explanation scores for the selected instance and convert to a dictionary\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m lime_exp_list = \u001b[43mexp_lime\u001b[49m.as_list()\n\u001b[32m      3\u001b[39m lime_scores = \u001b[38;5;28mdict\u001b[39m(lime_exp_list)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Compute SHAP explanation for the same instance (using KernelExplainer)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Note: Here we use explainer_shap for one instance. The output is a list of arrays.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'exp_lime' is not defined"
     ]
    }
   ],
   "source": [
    "# Get LIME explanation scores for the selected instance and convert to a dictionary\n",
    "lime_exp_list = exp_lime.as_list()\n",
    "lime_scores = dict(lime_exp_list)\n",
    "\n",
    "# Compute SHAP explanation for the same instance (using KernelExplainer)\n",
    "# Note: Here we use explainer_shap for one instance. The output is a list of arrays.\n",
    "shap_val_instance = explainer_shap.shap_values(X_test[instance_idx].reshape(1, -1))[0][0]\n",
    "\n",
    "# Create a hybrid explanation by averaging scores from LIME and SHAP\n",
    "hybrid_scores = {}\n",
    "for idx, feature in enumerate(data.feature_names):\n",
    "    # LIME might not list every feature (if not important, assume 0)\n",
    "    lime_score = lime_scores.get(feature, 0)\n",
    "    shap_score = shap_val_instance[idx]\n",
    "    hybrid_scores[feature] = (lime_score + shap_score) / 2\n",
    "\n",
    "print(\"Hybrid Explanation Scores (Averaged LIME + SHAP):\")\n",
    "for feature, score in hybrid_scores.items():\n",
    "    print(f\"{feature}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0505d7-6e18-42d1-ab4d-97e1dbd6d3ab",
   "metadata": {},
   "source": [
    "## Benchmarking and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337422ed-2db0-4681-a15f-b8cb3c3ba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_metric(model, instance, explanation, num_features=3):\n",
    "    \"\"\"\n",
    "    Compute a simple fidelity score by perturbing the top features\n",
    "    identified by the explanation and measuring the drop in prediction probability.\n",
    "    \"\"\"\n",
    "    # Make a copy of the instance and create a baseline (zero vector)\n",
    "    instance_perturbed = instance.copy()\n",
    "    baseline = np.zeros_like(instance)\n",
    "    \n",
    "    # Get the top features (sorted by the absolute importance score)\n",
    "    sorted_features = sorted(explanation.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    features_to_remove = [feat for feat, _ in sorted_features[:num_features]]\n",
    "    \n",
    "    # Perturb these features (set them to baseline)\n",
    "    for feature in features_to_remove:\n",
    "        idx = list(data.feature_names).index(feature)\n",
    "        instance_perturbed[idx] = baseline[idx]\n",
    "    \n",
    "    # Compute prediction before and after perturbation\n",
    "    original_pred = model.predict(instance.reshape(1, -1))[0][0]\n",
    "    perturbed_pred = model.predict(instance_perturbed.reshape(1, -1))[0][0]\n",
    "    \n",
    "    fidelity = original_pred - perturbed_pred\n",
    "    return fidelity\n",
    "\n",
    "# Compute fidelity for our chosen instance using LIME explanation\n",
    "fidelity_score = fidelity_metric(model_tabular, X_test[instance_idx].copy(), lime_scores, num_features=3)\n",
    "print(\"Fidelity Score (LIME):\", fidelity_score)\n",
    "\n",
    "def compute_average_fidelity(model, X, explainer, num_samples=10, num_features=3):\n",
    "    fidelities = []\n",
    "    for i in range(num_samples):\n",
    "        instance = X[i].copy()\n",
    "        # Get LIME explanation for the instance\n",
    "        exp = explainer.explain_instance(instance, model_predict, num_features=5)\n",
    "        exp_dict = dict(exp.as_list())\n",
    "        fidelity = fidelity_metric(model, instance, exp_dict, num_features=num_features)\n",
    "        fidelities.append(fidelity)\n",
    "    return np.mean(fidelities)\n",
    "\n",
    "avg_fidelity_lime = compute_average_fidelity(model_tabular, X_test, explainer_lime, num_samples=10, num_features=3)\n",
    "print(\"Average Fidelity (LIME):\", avg_fidelity_lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9747f-9b48-407f-b18e-5307a82d4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_metric(model, instance, explanation, num_features=3):\n",
    "    \"\"\"\n",
    "    Compute a fidelity score by perturbing the top features\n",
    "    identified by the explanation and measuring the drop in prediction probability.\n",
    "    \"\"\"\n",
    "    instance_perturbed = instance.copy()\n",
    "    baseline = np.zeros_like(instance)\n",
    "    \n",
    "    # Sort features by absolute importance and choose the top ones\n",
    "    sorted_features = sorted(explanation.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    features_to_remove = [feat for feat, _ in sorted_features[:num_features]]\n",
    "    \n",
    "    # Perturb the chosen features (set them to baseline)\n",
    "    for feature in features_to_remove:\n",
    "        idx = list(data.feature_names).index(feature)\n",
    "        instance_perturbed[idx] = baseline[idx]\n",
    "    \n",
    "    original_pred = model.predict(instance.reshape(1, -1))[0][0]\n",
    "    perturbed_pred = model.predict(instance_perturbed.reshape(1, -1))[0][0]\n",
    "    \n",
    "    fidelity = original_pred - perturbed_pred\n",
    "    return fidelity\n",
    "\n",
    "# Example: Compute fidelity for the previously explained instance using LIME\n",
    "instance_idx = 1  # index used previously\n",
    "lime_fidelity = fidelity_metric(model_tabular, X_test[instance_idx].copy(), dict(exp_lime.as_list()), num_features=3)\n",
    "print(\"Fidelity Score (LIME) for instance\", instance_idx, \":\", lime_fidelity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
